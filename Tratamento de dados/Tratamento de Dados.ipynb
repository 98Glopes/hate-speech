{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1c4bb61c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import nltk\n",
    "import json\n",
    "import requests\n",
    "import zipfile\n",
    "import shutil\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import category_encoders as ce"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c59b5e5c",
   "metadata": {},
   "source": [
    "# Tratamento de Dados\n",
    "-------\n",
    "## Objetivos\n",
    "```\n",
    "Fazer o download dos datasets escolhidos e fazer o tratamento para desenvolvimento dos experimentos\n",
    "```\n",
    "## Etapas do tratamento\n",
    "* `Download dos datasets`\n",
    "* `Agrupar e filtrar as categorias de discurso de ódio escolhidas`\n",
    "* `Separar todas as palavras de cada categoria`\n",
    "* `Analise qualtiativa das palavras mais importantes`\n",
    "## Classes de discurso de ódio analisdas\n",
    "| Classe    |\n",
    "|-----------|\n",
    "| Racismo   |\n",
    "| Sexismo   | \n",
    "| Homofobia |\n",
    "\n",
    "Também serão consideradas as amostras sem discurso de ódio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14b35b8e",
   "metadata": {},
   "source": [
    "## Dataset: Fortuna et Al, 2019\n",
    "### A hierarchically-labeled portuguese hate speech dataset\n",
    "```\n",
    "FORTUNA, Paula et al. A hierarchically-labeled portuguese hate speech dataset. In: Workshop on Abusive Language Online, 3º, 2019, Florence. Proceedings of the Third Workshop on Abusive Language Online. Florence: ACL | ALW | WS, 2019. p. 94-104.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f6bcddb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_url = 'https://raw.githubusercontent.com/paulafortuna/Portuguese-Hate-Speech-Dataset/master/2019-05-28_portuguese_hate_speech_hierarchical_classification.csv'\n",
    "classes_url = 'https://raw.githubusercontent.com/paulafortuna/Portuguese-Hate-Speech-Dataset/master/graph_hierarchical_classes.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "b1e56957",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(dataset_url)\n",
    "classes = pd.read_csv(classes_url)\n",
    "# print(dataset.columns[1:])\n",
    "target_classes = ['Sexism', 'Homophobia', 'Racism']\n",
    "\n",
    "# filter only non hate speech samples\n",
    "final_dataset = dataset[dataset['Hate.speech'] == 0]\n",
    "\n",
    "# add target classes\n",
    "for _class in target_classes:\n",
    "    final_dataset = pd.concat(\n",
    "        [final_dataset, dataset[dataset[_class] == 1].copy()]\n",
    "    )\n",
    "\n",
    "# removen unsude columns\n",
    "final_dataset = final_dataset[['text', 'Hate.speech', *target_classes]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "14528c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the dataset in disk\n",
    "final_dataset.to_csv(os.path.join('data', 'fortuna', 'fortuna.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "71070fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    " # get just words\n",
    "fortuna_words = {}\n",
    "\n",
    "for _class in ['Hate.speech', *target_classes]:\n",
    "    i = 0 if _class == 'Hate.speech' else 1\n",
    "    df = final_dataset[final_dataset[_class] == i]\n",
    "    df.apply((\n",
    "        lambda x: fortuna_words.setdefault(_class, []).extend(\n",
    "            nltk.word_tokenize(x['text'])\n",
    "        )\n",
    "    ), axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "1fe7088c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write words in disk\n",
    "with open(os.path.join('data', 'fortuna', 'words.json'), 'w') as f:\n",
    "    json.dump(fortuna_words, f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "134b0106",
   "metadata": {},
   "source": [
    "## Dataset:Ousidhoum, 2019\n",
    "###  Multilingual and multi-aspect hate speech analysis\n",
    "```\n",
    "OUSIDHOUM, Nedjma et al. Multilingual and multi-aspect hate speech analysis. arXiv preprint arXiv:1908.11049, 2019.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ba14a5d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# download dataset from gihub\n",
    "url = \"https://github.com/HKUST-KnowComp/MLMA_hate_speech/blob/master/hate_speech_mlma.zip?raw=true\"\n",
    "\n",
    "with requests.get(url, stream=True) as r:\n",
    "    r.raise_for_status()\n",
    "    with open('temp.zip', 'wb') as f:\n",
    "        for chunk in r.iter_content(chunk_size=8192):\n",
    "            f.write(chunk)\n",
    "\n",
    "with zipfile.ZipFile('temp.zip', 'r') as zip:\n",
    "    zip.extractall()\n",
    "    \n",
    "dataset = pd.read_csv(os.path.join(\"hate_speech_mlma\", \"en_dataset.csv\"))\n",
    "\n",
    "shutil.rmtree('hate_speech_mlma')\n",
    "os.remove('temp.zip')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7ab2155",
   "metadata": {},
   "source": [
    "```\n",
    "<class 'pandas.core.frame.DataFrame'>\n",
    "RangeIndex: 5647 entries, 0 to 5646\n",
    "Data columns (total 7 columns):\n",
    " #   Column               Non-Null Count  Dtype \n",
    "---  ------               --------------  ----- \n",
    " 0   HITId                5647 non-null   int64 \n",
    " 1   tweet                5647 non-null   object\n",
    " 2   sentiment            5647 non-null   object\n",
    " 3   directness           5647 non-null   object\n",
    " 4   annotator_sentiment  5647 non-null   object\n",
    " 5   target               5647 non-null   object\n",
    " 6   group                5647 non-null   object\n",
    "dtypes: int64(1), object(6)\n",
    "memory usage: 308.9+ KB\n",
    "\n",
    "{\n",
    "        'sexual_orientation': 'Homophobia',\n",
    "        'gender': 'Sexism',\n",
    "        'orgin': 'Racism'\n",
    "    },\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d080f86b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter target class from dataset\n",
    "target_classes = ['sexual_orientation', 'gender', 'origin']\n",
    "final_dataset = dataset[dataset['target'].isin(target_classes)][['tweet', 'target']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0fdea54c",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = ce.OneHotEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "52e41d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "oh = encoder.fit_transform(final_dataset[['target']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "76cbb1e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>origin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>origin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gender</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>origin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>origin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5639</th>\n",
       "      <td>origin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5640</th>\n",
       "      <td>origin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5641</th>\n",
       "      <td>origin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5643</th>\n",
       "      <td>origin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5646</th>\n",
       "      <td>origin</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3600 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      target\n",
       "0     origin\n",
       "3     origin\n",
       "4     gender\n",
       "5     origin\n",
       "6     origin\n",
       "...      ...\n",
       "5639  origin\n",
       "5640  origin\n",
       "5641  origin\n",
       "5643  origin\n",
       "5646  origin\n",
       "\n",
       "[3600 rows x 1 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_dataset[['target']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f31b1f6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
